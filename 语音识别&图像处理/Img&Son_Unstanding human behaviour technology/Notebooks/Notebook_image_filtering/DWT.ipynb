{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\" display: block; text-align: center; color: #FFFFFF; padding: 0.4em 0.5em;background: #303030;\">  DTW Discrete Wavelet Transform  </span>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"padding: 0.4em 0.5em; color: #494949; background: #f4f4f4; border-left: solid 5px #7db4e6; border-bottom: solid 3px #d7d7d7;\">1. Decomposition</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wavelet decomposition is a succession of filters and downsampling. \n",
    "<p/>\n",
    "<img src=\"img/decomposition.png\" width=800>\n",
    "<p/>\n",
    "You will code this decomposition in python step by step in the following subsections.\n",
    "\n",
    "To help you, you will have code to fill in. Each of the following subsections will indicate which function to complete. \n",
    "\n",
    "To test, you will use a synthetic file you can find just below, or the famous Lena bmp file, you can easily find on the net. Make sure of taking the bmp file (not a compressed file).\n",
    "\n",
    "<img src=\"img/imsynth.bmp\" width=64>\n",
    "\n",
    "Now you have everything to start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The image is 64 pixels wide and 64 pixels high.\n"
     ]
    }
   ],
   "source": [
    "import cv2 # install opencv-python\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "img = cv2.imread('img/imsynth.bmp',cv2.IMREAD_GRAYSCALE) # read the image\n",
    "#img = cv2.imread('img/Lena.bmp',cv2.IMREAD_GRAYSCALE) # read the image\n",
    "print(\"\")\n",
    "print(\"The image is \" + str(len(img[0])) + \" pixels wide and \" + str(len(img)) + \" pixels high.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"border-bottom: double 5px #7db4e6; color: #494949;\">1.1. Filtering in one direction</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the basic tool is filtering. In wavelet decomposition, it is done in one direction (x axis) and then in the other direction (y axis).\n",
    "\n",
    "Let's first create a generic function for filtering in one direction (x axis). <b>img</b> is the image you want to filter and <b>kernel</b> is a vector with the weights of the filter.\n",
    "\n",
    "You need to fill in the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# FUNCTIONS\n",
    "#-------------------------------\n",
    "# 1.1 Convolution in one direction\n",
    "def convOneDirection (img, kernel) :\n",
    "    h = len(kernel)//2\n",
    "    img_conv = np.zeros(img.shape)\n",
    "    for i in range (0, len(img)):\n",
    "        for j in range(h, len(img[0])-h):\n",
    "            TBC\n",
    "            img_conv[i][j] = TBC\n",
    "    return img_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div id=\"back_1\">\n",
    "   <a href=\"#sol_1\">Go to one solution.</a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify this function on an image with a low-pass filter kernel ([-1 2 6 2 -1]) and with a high-pass filter kernel ([-4 8 -4]) for instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TBC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1dbd694dd809>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#-------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimg_comp_lowpassfilter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvOneDirection\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mimg_comp_highpassfilter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvOneDirection\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-5aace8671352>\u001b[0m in \u001b[0;36mconvOneDirection\u001b[0;34m(img, kernel)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mTBC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mimg_conv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTBC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg_conv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TBC' is not defined"
     ]
    }
   ],
   "source": [
    "#-------------------------------\n",
    "# 1.1 FILTRERING IN ONE DIRECTION\n",
    "#-------------------------------\n",
    "print(\"\")\n",
    "img_comp_lowpassfilter = convOneDirection (img, [-1, 2, 6, 2, -1]) \n",
    "img_comp_highpassfilter = convOneDirection (img, [-2, 4, -2]) \n",
    "plt.subplot(1,3,1),plt.imshow(img, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,3,2),plt.imshow(img_comp_lowpassfilter, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,3,3),plt.imshow(img_comp_highpassfilter, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For filtering in the other direction, instead of having another function (or add a parameter to this function), we will use a trick: mirror the matrix. If you mirror the matrix, do a convolution on x axis and mirror the matrix again, you have performed a convolution in the y axis direction. The mirror function is given later and is named mirrorMatrix. Note that this take time processing to do so ; in real life, we won't do so ;)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"border-bottom: double 5px #7db4e6; color: #494949;\">1.2. Downsample in one direction</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second tool for DWT is downsampling by 2. \n",
    "\n",
    "Downsampling will start form the first pixel after a low pass filter, and from the second pixel after a high pass filter. The generic function takes the information of the first pixel to start with (either 0 or 1).\n",
    "\n",
    "Fill in the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Downsampling in one direction\n",
    "def downsamplOneDirection(img,firstPoint): \n",
    "    img_downsampl = np.zeros((len(img), len(img[0])//2))\n",
    "    TBC\n",
    "    return img_downsampl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"back_2\">\n",
    "   <a href=\"#sol_2\">Go to one solution.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it with the Le Gall kernel wavelet to get this result:\n",
    "\n",
    "<img src=\"img/im2.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# 1.2 DOWNSAMPLE IN ONE DIRECTION\n",
    "#-------------------------------\n",
    "print(\"\")\n",
    "img_comp_lowpassfilter = convOneDirection (img, [-1, 2, 6, 2, -1]) \n",
    "img_comp_highpassfilter = convOneDirection (img, [-2, 4, -2]) \n",
    "img_comp_lowpassfilter = downsamplOneDirection (img_comp_lowpassfilter, 0) \n",
    "img_comp_highpassfilter = downsamplOneDirection (img_comp_highpassfilter, 1) \n",
    "plt.subplot(1,2,1),plt.imshow(img, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,4,3),plt.imshow(img_comp_lowpassfilter, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,4,4),plt.imshow(img_comp_highpassfilter, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For downsampling in the other direction, we will use the same trick as for convolution: mirror the matrix. The same mirror function named mirrorMatrix can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"border-bottom: double 5px #7db4e6; color: #494949;\">1.3. Decomposition</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole decomposition is made of convolutions and downsampling on both axis. We need one more function to miror a matrix (swap x and y axes).\n",
    "Understand the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Mirror the matrix\n",
    "def mirrorMatrix(img):\n",
    "    img_miror = np.zeros((len(img[0]), len(img)))\n",
    "    for i in range (0, len(img[0])):\n",
    "        for j in range(0, len(img)):\n",
    "            img_miror[i][j] = img[j][i]\n",
    "    return img_miror"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And complete the whole decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# 1.3 DECOMPOSITION\n",
    "#-------------------------------\n",
    "# Decomposition\n",
    "print(\"\")\n",
    "print(\"Image with max amplitude : \" + str(np.max(img)))\n",
    "print(\"Starting decomposition...\")\n",
    "coefMult = 8 # to keep integer for computation\n",
    "kernelL = [-1, 2, 6, 2, -1] # coefMult*[-1, 2, 6, 2, -1]/8\n",
    "kernelH = [-4, 8, -4] # coefMult*[-1, 2, -1]/2\n",
    "firstPointL = 0 # first pixel for low pass filters\n",
    "firstPointH = 1 # second pixel for high pass filters\n",
    "\n",
    "imgL = TBC\n",
    "imgLcopy = mirrorMatrix(deepcopy(imgL))\n",
    "imgLL = TBC\n",
    "imgLH = TBC\n",
    "imgH = TBC\n",
    "imgHcopy = mirrorMatrix(deepcopy(imgH))\n",
    "imgHL = TBC\n",
    "imgHH = TBC\n",
    "\n",
    "print(\"Decommposition finished\")\n",
    "print(\"Max amplitude of integer images are : \" + str(np.max(img)) + \" \" + str(np.max(imgL))+ \" \" + str(np.max(imgH))+ \" \" + str(np.max(imgLL))+ \" \" + str(np.max(imgLH))+ \" \" + str(np.max(imgHL))+ \" \" + str(np.max(imgHH)))\n",
    "print(\"The images are \" + str(len(imgLL[0])) + \" pixels wide and \" + str(len(imgLL)) + \" pixels high.\")\n",
    "\n",
    "# Verify by plotting the different images:\n",
    "plt.subplot(1,4,1),plt.imshow(img, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,8,3),plt.imshow(imgL, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,8,11),plt.imshow(imgH, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(4,8,4),plt.imshow(imgLL, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(4,8,12),plt.imshow(imgLH, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(4,8,20),plt.imshow(imgHL, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(4,8,28),plt.imshow(imgHH, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"back_3\">\n",
    "   <a href=\"#sol_3\">Go to one solution.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"padding: 0.4em 0.5em; color: #494949; background: #f4f4f4; border-left: solid 5px #7db4e6; border-bottom: solid 3px #d7d7d7;\">2. Reconstruction & Verification</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruction is the opposite process:\n",
    "    <p/>\n",
    "<img src=\"img/reconstruction.png\" width=800>\n",
    "<p/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"border-bottom: double 5px #7db4e6; color: #494949;\">2.1. Reconstruction</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function for upsampling is the following one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Upsampling in one direction\n",
    "def upsamplOneDirection(img,firstPoint): \n",
    "    img_upsubsampl = np.zeros((len(img), len(img[0])*2))\n",
    "    for i in range (0, len(img)):\n",
    "        for j in range (0, len(img[0])):\n",
    "            img_upsubsampl[i][j*2+firstPoint] = img[i][j]\n",
    "    return img_upsubsampl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the code of reconstruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# 2.1 RECONSTRUCTION\n",
    "#-------------------------------\n",
    "# Reconstruction\n",
    "print(\"\")\n",
    "print(\"Starting recontruction...\")\n",
    "kernelH = [-1, -2, 6, -2, -1] # coefMult*[-1, -2, 6, -2, -1]/8\n",
    "kernelL = [4, 8, 4] # coefMult*[1, 2, 1]/2\n",
    "irstPointL = 0 # first pixel for low pass filters\n",
    "firstPointH = 1 # second pixel for high pass filters\n",
    "\n",
    "imgRL1 = TBC\n",
    "imgRL2 = TBC\n",
    "imgRL = mirrorMatrix(imgRL1+imgRL2)\n",
    "imgRH1 = TBC\n",
    "imgRH2 = TBC \n",
    "imgRH = mirrorMatrix(imgRH1+imgRH2)\n",
    "imgR1 = TBC\n",
    "imgR2 = TBC\n",
    "imgR = imgR1 + imgR2\n",
    "plt.subplot(2, 8, 6),plt.imshow(imgRL, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2, 8, 14),plt.imshow(imgRH, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1, 4, 4),plt.imshow(imgR, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "print(\"Reconstruction finished\")\n",
    "print(\"Max amplitude of integer images are : \" + str(np.max(imgRL1)) + \" \" + str(np.max(imgRL2))+ \" \" + str(np.max(imgRH1))+ \" \" + str(np.max(imgRH2))+ \" \" + str(np.max(imgRL))+ \" \" + str(np.max(imgRH))+ \" \" + str(np.max(imgR1))+ \" \" + str(np.max(imgR2))+ \" \" + str(np.max(imgR)))\n",
    "print(\"The image is \" + str(len(imgR[0])) + \" pixels wide and \" + str(len(imgR)) + \" pixels high.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "<div id=\"back_4\">\n",
    "   <a href=\"#sol_4\">Go to one solution.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"border-bottom: double 5px #7db4e6; color: #494949;\">2.2. Verification</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On several images (imsynth.bmp, Lena.bmp, ...), verify that the image reconstructed is the same as the original image. Do not take into account the edges of the image (because we did not perform the convolution on those parts).\n",
    "\n",
    "You can fill in the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# 2.2 VERIFICATION\n",
    "#-------------------------------\n",
    "imgRCoef = imgR//coefMult**4 # coefMult**4 is due to the fact that we keep integers before - see kernel values\n",
    "print(\"\")\n",
    "print(\"Starting verification...\")\n",
    "edge = 3\n",
    "maskVerif = TBC\n",
    "print(\"Mask delta value : \" + str(np.max(maskVerif)) )\n",
    "maskVerif[0][0] = 0; maskVerif[0][1] = 255 # to avoid min-max equalization from matplotlib :)\n",
    "plt.imshow(maskVerif, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"back_5\">\n",
    "   <a href=\"#sol_5\">Go to one solution.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mask delta value should be 0 ! And you should have a black image (expect the 2nd pixel because... matplotlib... you know the story)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\" display: block; text-align: center; color: #FFFFFF; padding: 0.4em 0.5em;background: #303030;\">  Solutions </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"sol_1\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Convolution in one direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution in one direction\n",
    "def convOneDirection (img, kernel) :\n",
    "    h = len(kernel)//2\n",
    "    img_conv = np.zeros(img.shape)\n",
    "    for i in range (0, len(img)):\n",
    "        for j in range(h, len(img[0])-h):\n",
    "            sum=0\n",
    "            for m in range(len(kernel)):\n",
    "                sum=sum+kernel[m]*img[i][j-h+m]\n",
    "            img_conv[i][j] = sum\n",
    "    return img_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   <a href=\"#back_1\">Back.</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"sol_2\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Downsampling in one direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling in one direction\n",
    "def downsamplOneDirection(img,firstPoint): \n",
    "    img_downsampl = np.zeros((len(img), len(img[0])//2))\n",
    "    for i in range (0, len(img)):\n",
    "        for j in range (0, len(img[0])//2):\n",
    "            img_downsampl[i][j] = img[i][2*j+firstPoint]\n",
    "    return img_downsampl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   <a href=\"#back_2\">Back.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"sol_3\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# DECOMPOSITION\n",
    "#-------------------------------\n",
    "# Decomposition\n",
    "print(\"\")\n",
    "print(\"Image with max amplitude : \" + str(np.max(img)))\n",
    "print(\"Starting decomposition...\")\n",
    "coefMult = 8 # to keep integer for computation\n",
    "kernelL = [-1, 2, 6, 2, -1] # coefMult*[-1, 2, 6, 2, -1]/8\n",
    "kernelH = [-4, 8, -4] # coefMult*[-1, 2, -1]/2\n",
    "firstPointL = 0 # first pixel for low pass filters\n",
    "firstPointH = 1 # second pixel for high pass filters\n",
    "\n",
    "imgL = downsamplOneDirection(convOneDirection(img, kernelL), firstPointL) # LossPass Filter on width + downsample by 2\n",
    "imgLcopy = mirrorMatrix(deepcopy(imgL))\n",
    "imgLL = mirrorMatrix(downsamplOneDirection(convOneDirection(imgLcopy, kernelL), firstPointL)) # LossPass Filter on height + downsample by 2\n",
    "imgLH = mirrorMatrix(downsamplOneDirection(convOneDirection(imgLcopy, kernelH), firstPointH)) # HighPass Filter on height + downsample by 2\n",
    "imgH = downsamplOneDirection(convOneDirection(img, kernelH), firstPointH) # LossPass Filter on width + downsample by 2\n",
    "imgHcopy = mirrorMatrix(deepcopy(imgH))\n",
    "imgHL = mirrorMatrix(downsamplOneDirection(convOneDirection(imgHcopy, kernelL), firstPointL)) # LossPass Filter on height + downsample by 2\n",
    "imgHH = mirrorMatrix(downsamplOneDirection(convOneDirection(imgHcopy, kernelH), firstPointH)) # HighPass Filter on height + downsample by 2\n",
    "\n",
    "print(\"Decommposition finished\")\n",
    "print(\"Max amplitude of integer images are : \" + str(np.max(img)) + \" \" + str(np.max(imgL))+ \" \" + str(np.max(imgH))+ \" \" + str(np.max(imgLL))+ \" \" + str(np.max(imgLH))+ \" \" + str(np.max(imgHL))+ \" \" + str(np.max(imgHH)))\n",
    "print(\"The images are \" + str(len(imgLL[0])) + \" pixels wide and \" + str(len(imgLL)) + \" pixels high.\")\n",
    "\n",
    "# Verify by plotting the different images:\n",
    "plt.subplot(1,4,1),plt.imshow(img, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,8,3),plt.imshow(imgL, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,8,11),plt.imshow(imgH, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(4,8,4),plt.imshow(imgLL, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(4,8,12),plt.imshow(imgLH, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(4,8,20),plt.imshow(imgHL, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(4,8,28),plt.imshow(imgHH, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   <a href=\"#back_3\">Back.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"sol_4\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# RECONSTRUCTION\n",
    "#-------------------------------\n",
    "# Reconstruction\n",
    "print(\"\")\n",
    "print(\"Starting recontruction...\")\n",
    "kernelH = [-1, -2, 6, -2, -1] # coefMult*[-1, -2, 6, -2, -1]/8\n",
    "kernelL = [4, 8, 4] # coefMult*[1, 2, 1]/2\n",
    "irstPointL = 0 # first pixel for low pass filters\n",
    "firstPointH = 1 # second pixel for high pass filters\n",
    "\n",
    "imgRL1 = convOneDirection(upsamplOneDirection(mirrorMatrix(imgLL),firstPointL), kernelL)\n",
    "imgRL2 = convOneDirection(upsamplOneDirection(mirrorMatrix(imgLH),firstPointH), kernelH)\n",
    "imgRL = mirrorMatrix(imgRL1+imgRL2)\n",
    "imgRH1 = convOneDirection(upsamplOneDirection(mirrorMatrix(imgHL),firstPointL), kernelL) \n",
    "imgRH2 = convOneDirection(upsamplOneDirection(mirrorMatrix(imgHH),firstPointH), kernelH) \n",
    "imgRH = mirrorMatrix(imgRH1+imgRH2)\n",
    "imgR1 = convOneDirection(upsamplOneDirection(imgRL,firstPointL), kernelL)\n",
    "imgR2 = convOneDirection(upsamplOneDirection(imgRH,firstPointH), kernelH)\n",
    "imgR = imgR1 + imgR2\n",
    "plt.subplot(2, 8, 6),plt.imshow(imgRL, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2, 8, 14),plt.imshow(imgRH, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1, 4, 4),plt.imshow(imgR, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "print(\"Reconstruction finished\")\n",
    "print(\"Max amplitude of integer images are : \" + str(np.max(imgRL1)) + \" \" + str(np.max(imgRL2))+ \" \" + str(np.max(imgRH1))+ \" \" + str(np.max(imgRH2))+ \" \" + str(np.max(imgRL))+ \" \" + str(np.max(imgRH))+ \" \" + str(np.max(imgR1))+ \" \" + str(np.max(imgR2))+ \" \" + str(np.max(imgR)))\n",
    "print(\"The image is \" + str(len(imgR[0])) + \" pixels wide and \" + str(len(imgR)) + \" pixels high.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   <a href=\"#back_4\">Back.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"sol_5\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# VERIFICATION\n",
    "#-------------------------------\n",
    "imgRCoef = imgR//coefMult**4 # coefMult**4 is due to the fact that we keep integers before - see kernel values\n",
    "print(\"\")\n",
    "print(\"Starting verification...\")\n",
    "edge = 3\n",
    "maskVerif = np.abs((img-imgRCoef)[edge:len(img)-edge, edge:len(img[0])-edge]) # difference between the 2 images, without the edges \n",
    "print(\"Mask delta value : \" + str(np.max(maskVerif)) )\n",
    "maskVerif[0][0] = 0; maskVerif[0][1] = 255 # to avoid min-max equalization from matplotlib :)\n",
    "plt.imshow(maskVerif, cmap = 'gray'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   <a href=\"#back_5\">Back.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
