{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5-final"},"colab":{"name":"Transformer Language Models.ipynb","provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"e133b519510a40da8a5b570f760bf8ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a41cdb5ecea047b3a1fb36cb406a0f9c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8a40e5aac71644da883032053f5f0f84","IPY_MODEL_18b0892231d74ac09e68c04addb87c2d"]}},"a41cdb5ecea047b3a1fb36cb406a0f9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8a40e5aac71644da883032053f5f0f84":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1841077127564692897308765adc3312","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9cffbbbdfb464f8285b54a1b0089cef4"}},"18b0892231d74ac09e68c04addb87c2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_70fe8e122aa44cfcb4a590d8d607c18f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 521kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_031db70bccb64d84ba96bcdc7f3a8e14"}},"1841077127564692897308765adc3312":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9cffbbbdfb464f8285b54a1b0089cef4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"70fe8e122aa44cfcb4a590d8d607c18f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"031db70bccb64d84ba96bcdc7f3a8e14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ffcd7d57b1bf4047bf2d732cedc140fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_094f3fcaa91343a4870dc25bf2434d37","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ed3e5079a2764b67bc89460e1d810e41","IPY_MODEL_4735781a1a5643aa855c36327d5d688e"]}},"094f3fcaa91343a4870dc25bf2434d37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed3e5079a2764b67bc89460e1d810e41":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bd44b63b804444708dcfb992942a2df3","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":48,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":48,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ddaa3b4a520f4c3a86dafa87c8ebc5b3"}},"4735781a1a5643aa855c36327d5d688e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c7c5760e443743a8868adcdb113d0a71","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 48.0/48.0 [00:00&lt;00:00, 392B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6796be185a7d4c37b07a2ab552739014"}},"bd44b63b804444708dcfb992942a2df3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ddaa3b4a520f4c3a86dafa87c8ebc5b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c7c5760e443743a8868adcdb113d0a71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6796be185a7d4c37b07a2ab552739014":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0b87e44da1b94774a6cadad0389fbd58":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1769b0825e9142439cde705f7ee822b0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a633919af43e448dab7f7086af0094ad","IPY_MODEL_4ad960b2bc3545a4ae391aba0bd29c1d"]}},"1769b0825e9142439cde705f7ee822b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a633919af43e448dab7f7086af0094ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c8f17dcbf0814c03b357a549e07d36fe","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":629,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":629,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f7cea372a71f4fbf93d36a85f36ff97f"}},"4ad960b2bc3545a4ae391aba0bd29c1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_24fdc738b1f945b89560fc9df3a812e9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 629/629 [00:00&lt;00:00, 2.66kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2c12c50b02894f12adb89e60b089dbc6"}},"c8f17dcbf0814c03b357a549e07d36fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f7cea372a71f4fbf93d36a85f36ff97f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"24fdc738b1f945b89560fc9df3a812e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2c12c50b02894f12adb89e60b089dbc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7db8f8a09671410999442f1f899756b2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_aa442a93cb0a40128e425e234f3d1926","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c2cede54e3eb46a581532f0972a2a357","IPY_MODEL_05ba3a3a970045a0801612343ec89f28"]}},"aa442a93cb0a40128e425e234f3d1926":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c2cede54e3eb46a581532f0972a2a357":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_de4ce5a51d3543e2874f370af0ac79d3","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":267844284,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":267844284,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_68e2a4fc3fde4d919ead9438c880035c"}},"05ba3a3a970045a0801612343ec89f28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d7a7a7ad3d644aa28d4e8e0983d73023","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 268M/268M [00:06&lt;00:00, 41.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_869a7f31fca74c70b9feb60ce68ed107"}},"de4ce5a51d3543e2874f370af0ac79d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"68e2a4fc3fde4d919ead9438c880035c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7a7a7ad3d644aa28d4e8e0983d73023":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"869a7f31fca74c70b9feb60ce68ed107":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"moved-gasoline","executionInfo":{"status":"ok","timestamp":1614766862703,"user_tz":-60,"elapsed":12822,"user":{"displayName":"Xinjian OUYANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64","userId":"04586718377978961617"}},"outputId":"79d21d88-4bf4-4180-fcaf-6692b8c9f67a"},"source":["from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n","import torch\n","import pandas as pd"],"id":"moved-gasoline","execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"welcome-housing"},"source":["# Transformer Language Models\n","### For sentiment analysis\n","Author: [Camilo](https://github.com/camilocarvajalreyes/)\n","\n","**Objectives**: You will get familiarised with the use of pre-trained models, how to interpret them and implement them in a simple NLP pipeline.\n","\n","**To do**: Trying a [pre-trained](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english) sentiment classifier based on Transformers in an industry case! \n","\n","### Instructions\n","1. Download the vectors, install packages and test if everything is okay (if you haven't done so yet)\n","2. Load the packages and import vectors by running cells in section 0. We will get familiarised with a pre-trained model that uses Transformers from HuggingFace\n","3. Read the instructions in Section 1 and implement the model in a sentiment classifiction task.\n","4. In section 2 we will see how to visualise the attention weights of the model for some examples\n","5. Don't forget to ask if you have any question\n","\n","## Section 0 - Importing a pre-trained model\n","In this tutorial we will use a library called **transformers** from the French company **HuggingFace**. [Transformers](https://github.com/huggingface/transformers) offers more than 40 architectures for NLP based on the [the original transformer module](https://arxiv.org/abs/1706.03762)."],"id":"welcome-housing"},{"cell_type":"markdown","metadata":{"id":"viral-contributor"},"source":["We'll use [distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n","\n","This model is a based on the [distilBERT](https://arxiv.org/abs/1910.01108), a lighter version of [BERT](https://arxiv.org/abs/1810.04805) and it has been trained for the [Stanford Sentiment Analysis dataset](https://paperswithcode.com/dataset/sst)"],"id":"viral-contributor"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":213,"referenced_widgets":["e133b519510a40da8a5b570f760bf8ce","a41cdb5ecea047b3a1fb36cb406a0f9c","8a40e5aac71644da883032053f5f0f84","18b0892231d74ac09e68c04addb87c2d","1841077127564692897308765adc3312","9cffbbbdfb464f8285b54a1b0089cef4","70fe8e122aa44cfcb4a590d8d607c18f","031db70bccb64d84ba96bcdc7f3a8e14","ffcd7d57b1bf4047bf2d732cedc140fa","094f3fcaa91343a4870dc25bf2434d37","ed3e5079a2764b67bc89460e1d810e41","4735781a1a5643aa855c36327d5d688e","bd44b63b804444708dcfb992942a2df3","ddaa3b4a520f4c3a86dafa87c8ebc5b3","c7c5760e443743a8868adcdb113d0a71","6796be185a7d4c37b07a2ab552739014","0b87e44da1b94774a6cadad0389fbd58","1769b0825e9142439cde705f7ee822b0","a633919af43e448dab7f7086af0094ad","4ad960b2bc3545a4ae391aba0bd29c1d","c8f17dcbf0814c03b357a549e07d36fe","f7cea372a71f4fbf93d36a85f36ff97f","24fdc738b1f945b89560fc9df3a812e9","2c12c50b02894f12adb89e60b089dbc6","7db8f8a09671410999442f1f899756b2","aa442a93cb0a40128e425e234f3d1926","c2cede54e3eb46a581532f0972a2a357","05ba3a3a970045a0801612343ec89f28","de4ce5a51d3543e2874f370af0ac79d3","68e2a4fc3fde4d919ead9438c880035c","d7a7a7ad3d644aa28d4e8e0983d73023","869a7f31fca74c70b9feb60ce68ed107"]},"id":"mobile-worship","executionInfo":{"status":"ok","timestamp":1614766878314,"user_tz":-60,"elapsed":9999,"user":{"displayName":"Xinjian OUYANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64","userId":"04586718377978961617"}},"outputId":"af58b6bd-9032-4361-f3c3-0c419258644d"},"source":["MODEL_NAME = \"distilbert-base-uncased-finetuned-sst-2-english\"\n","\n","tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)\n","model = DistilBertForSequenceClassification.from_pretrained(MODEL_NAME)"],"id":"mobile-worship","execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"undefined-assessment"},"source":["First of all we need to do some pre-processing on the input text. Fortunately, HuggingFace includes **Tokenizers** from pre-trained models.\n","\n","Applying this particular pre-trained model to a tokenised input returns a [SequenceClassifierOutput](https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput) object. More precisely, we can get the **logit** values, which reflect the probability of a Class to be chosen over the other ones.\n","\n","In this case, we have a **binary sentiment classification**, thus the the logits vector show the odds of the sample being **negative** or **positive** respectively."],"id":"undefined-assessment"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"funded-might","executionInfo":{"status":"ok","timestamp":1614766882337,"user_tz":-60,"elapsed":856,"user":{"displayName":"Xinjian OUYANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64","userId":"04586718377978961617"}},"outputId":"94d670ac-e16d-4d6c-e51d-bc35b57467e8"},"source":["input_example = tokenizer(\"The cutest dog I've ever seen\", return_tensors=\"pt\")\n","output = model(**input_example)\n","#logits = outputs.logits\n","#print(logits)\n","print('Output:')\n","print(output)\n","print('Logits:')\n","print(output.logits)"],"id":"funded-might","execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"friendly-underwear"},"source":["Furthermore, if we happen to have labels for our samples, we can add them when calling the model and it will output the corresponding **loss**. In this case, we know that our phrase is **positive**, the label should be **1**"],"id":"friendly-underwear"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"accepted-insured","executionInfo":{"status":"ok","timestamp":1614766971502,"user_tz":-60,"elapsed":604,"user":{"displayName":"Xinjian OUYANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64","userId":"04586718377978961617"}},"outputId":"42291ac2-40d0-4261-b743-9b9336fe4a87"},"source":["label = torch.tensor([1]).unsqueeze(0)  # Batch size 1, postive sentiment (label 1)\n","output = model(**input_example, labels=label) \n","print(output.loss)"],"id":"accepted-insured","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"joint-bedroom"},"source":["Both outputs are PyTorch tensors, but we can transform it to a **numpy array**.\n","\n","Remark: the first dimension is 1 because it corresponds to the batch size, which is one since we are only inputing one example"],"id":"joint-bedroom"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"superior-inventory","executionInfo":{"status":"ok","timestamp":1614766977492,"user_tz":-60,"elapsed":534,"user":{"displayName":"Xinjian OUYANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64","userId":"04586718377978961617"}},"outputId":"5484aae2-b305-4a04-a6e4-281d75dc9616"},"source":["tensor = output.logits\n","array = tensor.detach().numpy()\n","print(array.shape)\n","print(array)"],"id":"superior-inventory","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"opponent-brunswick"},"source":["## Section 1 - Clasifying tweets\n","Let's consider a real case scenario: a major **US Airline** needs you to classify tweets from its costumers. They provide the following [dataset](https://www.kaggle.com/crowdflower/twitter-airline-sentiment):\n","\n","Since we won't fine tune the mode, we will only take 2000 out of the ~14000 tweets"],"id":"opponent-brunswick"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"cordless-afghanistan","executionInfo":{"status":"error","timestamp":1614766987461,"user_tz":-60,"elapsed":540,"user":{"displayName":"Xinjian OUYANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64","userId":"04586718377978961617"}},"outputId":"b92da1a2-bb6c-44e2-a4db-76d25e476337"},"source":["full_dataset = pd.read_csv(\"data/Tweets-subset.csv\")\n","pd.set_option('max_colwidth', 120)\n","full_dataset = full_dataset.drop(['tweet_id','negativereason','negativereason_confidence','retweet_count',\n","             'airline','airline_sentiment_gold','name','negativereason_gold',\n","             'tweet_coord','tweet_created','tweet_location','user_timezone'], axis=1)\n","dataset = full_dataset[(full_dataset['airline_sentiment']!='neutral')]\n","\n","# example sentence \n","index = 16\n","print(dataset.iloc[index].text)\n","\n","dataset.head()"],"id":"cordless-afghanistan","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"approved-diameter"},"source":["**1. Using our pre-trained Model, code a function that takes a string of text and outputs 1 if it's positive and 0 if negative**"],"id":"approved-diameter"},{"cell_type":"code","metadata":{"id":"bridal-service","executionInfo":{"status":"aborted","timestamp":1614766817764,"user_tz":-60,"elapsed":2139,"user":{"displayName":"Xinjian OUYANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64","userId":"04586718377978961617"}}},"source":["### to do ###"],"id":"bridal-service","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"architectural-foster"},"source":["**2. Iterate over the dataset and compute the average loss and the accuracy of the classifier**\n","\n","(This cell should take about 1 minute to run)"],"id":"architectural-foster"},{"cell_type":"code","metadata":{"id":"clean-defendant","executionInfo":{"status":"aborted","timestamp":1614766817764,"user_tz":-60,"elapsed":2137,"user":{"displayName":"Xinjian OUYANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64","userId":"04586718377978961617"}}},"source":["for index, row in dataset.iterrows():\n","    text = row.text\n","    ### to do ###\n","    \n","print('average loss = {}'.format(average_loss))\n","print('accuracy = {}'.format(accuracy))"],"id":"clean-defendant","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"natural-civilian"},"source":["### Visualising Attention\n","\n","The airline wishes to understand how the model works. Therefore, you decide to show a visualisation of the attention weights from the first and last layer of transformers. Thankfully, Transformers provides the attention weights when output_attentions=True"],"id":"natural-civilian"},{"cell_type":"code","metadata":{"id":"thermal-asian","executionInfo":{"status":"aborted","timestamp":1614766817765,"user_tz":-60,"elapsed":2136,"user":{"displayName":"Xinjian OUYANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64","userId":"04586718377978961617"}}},"source":["def attention(list_text,layer=0):\n","    ''' parameters:\n","    text: input string for the classifier\n","    layer: layer to show the attention weights from\n","    '''\n","    input_sentence = tokenizer(list_text, return_tensors=\"pt\",is_split_into_words=True)\n","    output = model(**input_sentence,output_attentions=True)\n","    print('text: '+list_text)\n","    array = output.attentions[layer].detach().numpy()\n","    array = array.mean(axis=1) # taking average over all attention heads\n","    return array[0,:,:]\n","\n","#example\n","#attention(\"@VirginAmerica and it's a really big bad thing about it\")"],"id":"thermal-asian","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hawaiian-receiver"},"source":["**3. Using the attention function, code a heatmap to visualise the scoresfrom the model's self attention**\n","\n","You can take inspiration from [this example](https://matplotlib.org/stable/gallery/images_contours_and_fields/image_annotated_heatmap.html)"],"id":"hawaiian-receiver"},{"cell_type":"code","metadata":{"id":"genuine-flavor","executionInfo":{"status":"aborted","timestamp":1614766817765,"user_tz":-60,"elapsed":2134,"user":{"displayName":"Xinjian OUYANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64","userId":"04586718377978961617"}}},"source":["import matplotlib.pyplot as plt\n","plt.rcParams[\"figure.figsize\"] = (10,6) # setting figure size\n","\n","def heatmap_attention(text,layer=0):\n","    tokenized_sequence = tokenizer.tokenize(text)\n","    labels = ['[CLS]']+tokenized_sequence+['[SEP]']\n","\n","    matrix = ### to do ###\n","\n","\n","    fig, ax = plt.subplots()\n","    im = ax.imshow(matrix)\n","\n","    # We want to show all ticks...\n","    \n","    ### to do ###\n","    \n","    # ... and label them with the respective list entries\n","    \n","    ### to do ###\n","    \n","    # Rotate the tick labels and set their alignment.\n","    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n","             rotation_mode=\"anchor\")\n","\n","    ax.set_title(\"Attention visualisation for our Transformer based classifier\")\n","    fig.tight_layout()\n","    plt.show()"],"id":"genuine-flavor","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"union-eugene","executionInfo":{"status":"aborted","timestamp":1614766817766,"user_tz":-60,"elapsed":2133,"user":{"displayName":"Xinjian OUYANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64","userId":"04586718377978961617"}}},"source":["heatmap_attention(\"@VirginAmerica and it's a really big bad thing about it\")"],"id":"union-eugene","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"refined-horizontal"},"source":["### Bonus task\n","In order to make the task simpler, we have so far ignored neutral tweets."],"id":"refined-horizontal"},{"cell_type":"code","metadata":{"id":"comprehensive-chamber","executionInfo":{"status":"aborted","timestamp":1614766817767,"user_tz":-60,"elapsed":2131,"user":{"displayName":"Xinjian OUYANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64","userId":"04586718377978961617"}}},"source":["full_dataset[(full_dataset['airline_sentiment']=='neutral')].head()"],"id":"comprehensive-chamber","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"through-possible"},"source":["**Design a way of predicting that the tweet is neutral**\n","\n","You may use the attribute **logits** from the model's output"],"id":"through-possible"},{"cell_type":"code","metadata":{"id":"mechanical-publicity","executionInfo":{"status":"aborted","timestamp":1614766817767,"user_tz":-60,"elapsed":2129,"user":{"displayName":"Xinjian OUYANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64","userId":"04586718377978961617"}}},"source":["### to do ###"],"id":"mechanical-publicity","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fluid-demographic"},"source":["### Section 2: More on HuggingFace's transformers\n","\n","We have used a pre-trained model, but we can fine-tune it for our specific task or data-set. You can find the instructions for doing so in [this tutorial](https://github.com/huggingface/notebooks/blob/master/examples/text_classification.ipynb)\n","\n","Furthermore, there's an even simpler way of using HuggingFace's pre-trained models: [pipelines](https://github.com/huggingface/transformers/blob/master/notebooks/03-pipelines.ipynb)"],"id":"fluid-demographic"},{"cell_type":"code","metadata":{"id":"german-lawyer","executionInfo":{"status":"aborted","timestamp":1614766817768,"user_tz":-60,"elapsed":2128,"user":{"displayName":"Xinjian OUYANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64","userId":"04586718377978961617"}}},"source":["from transformers import pipeline"],"id":"german-lawyer","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vulnerable-trunk"},"source":["**Example using a sentiment classification task:**"],"id":"vulnerable-trunk"},{"cell_type":"code","metadata":{"id":"quiet-reverse","executionInfo":{"status":"aborted","timestamp":1614766817768,"user_tz":-60,"elapsed":2127,"user":{"displayName":"Xinjian OUYANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64","userId":"04586718377978961617"}}},"source":["nlp_sentence_classif = pipeline('sentiment-analysis')\n","nlp_sentence_classif(\"@VirginAmerica and it's a really big bad thing about it\")"],"id":"quiet-reverse","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hourly-superior"},"source":["**Example of machine translation**"],"id":"hourly-superior"},{"cell_type":"code","metadata":{"id":"extra-trauma","executionInfo":{"status":"aborted","timestamp":1614766817769,"user_tz":-60,"elapsed":2120,"user":{"displayName":"Xinjian OUYANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64","userId":"04586718377978961617"}}},"source":["# English to French\n","translator = pipeline('translation_en_to_fr')\n","translator(\"HuggingFace is a French company that is based in New York City. HuggingFace's mission is to solve NLP one commit at a time\")"],"id":"extra-trauma","execution_count":null,"outputs":[]}]}