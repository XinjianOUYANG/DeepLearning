{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "secure-beaver",
   "metadata": {},
   "source": [
    "# Visualisation of semantic relations\n",
    "### Using word embeddings\n",
    "\n",
    "Author: [Camilo](https://github.com/camilocarvajalreyes)\n",
    "\n",
    "**Objectives**: You should gain intuition on what kind of information gets\n",
    "encoded in word representations and how to visualise it.\n",
    "\n",
    "\n",
    "**To do**: You will code a **PCA visualisation** of semantic relations using\n",
    "GloVe. They can base their algorithm in an example given with\n",
    "countries and capitals.\n",
    "\n",
    "## Instructions\n",
    "1. Download the vectors, install packages and test if everything is okay (if you haven't done so yet)\n",
    "2. Load the packages and import vectors by running cells in section 0\n",
    "3. Take a look at the code below in which we visualise the GloVe embedding space\n",
    "4. Based on the given code, make your own PCA visualisation of semantic relations.\n",
    "5. Don't forget to ask if you have any question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-occasions",
   "metadata": {},
   "source": [
    "## Section 0\n",
    "Loading packages and importing pre-trained vectors. **Run all cells in this section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # visualisation\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6) # setting figure size\n",
    "import numpy as np # for operations with vectors\n",
    "import csv # opening csv files\n",
    "import pickle # opening pickled dictionary with vectors\n",
    "from sklearn.decomposition import PCA # dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-discharge",
   "metadata": {},
   "source": [
    "**GloVe pre-trained vectors**\n",
    "\n",
    "\n",
    "First we import a pickled dictionary with GloVe pre-trained vectors. We only import the vectors with the words we'll use in this notebook. For full vocabularies see [Stanford-GloVe](https://nlp.stanford.edu/projects/glove/).\n",
    "\n",
    "Pennington, J., Socher, R., & Manning, C. D. (2014, October). [Glove: Global vectors for word representation](https://www.aclweb.org/anthology/D14-1162.pdf). In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) (pp. 1532-1543)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_path = 'data/glove_subset.pickle' # change path if necessary\n",
    "with open(vectors_path, 'rb') as handle:\n",
    "    vecs = pickle.load(handle)\n",
    "    \n",
    "# example\n",
    "print('vector length = '+str(len(vecs['france'])))\n",
    "vecs['france'][:5] # first five values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-customs",
   "metadata": {},
   "source": [
    "## Section 1: Visualising country-capital relation\n",
    "Below there's an example of semantic relation visualisation.\n",
    "\n",
    "We'll store capitals and countries in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_country={}\n",
    "with open('data/country_list.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        country=row[0]\n",
    "        country=country.lower().replace(' ','_') # remove upper case and add _ for n-grams\n",
    "        capital=row[1]\n",
    "        capital=capital.lower().replace(' ','_')\n",
    "        try:\n",
    "            vecs[capital]\n",
    "            vecs[country]\n",
    "            capital_country[country] = capital\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "all_words = [word for word in capital_country.keys()]+[word for word in capital_country.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-defensive",
   "metadata": {},
   "source": [
    "**Dimensionality reduction using [PCA](https://scikit-learn.org/stable/modules/decomposition.html#pca)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vectors = [vecs[word] for word in all_words]\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_vecs = pca.fit_transform(all_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-pixel",
   "metadata": {},
   "source": [
    "Visualisation using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = ['tab:blue']*len(capital_country)+['tab:orange']*len(capital_country)\n",
    "x_vecs, y_vecs = [v[0] for v in pca_vecs], [v[1] for v in pca_vecs]\n",
    "plt.scatter(x_vecs, y_vecs, c=colours)\n",
    "plt.title('Visualisation of GloVe - countries and capitals')\n",
    "\n",
    "labels = ['chile','santiago','france','paris','canada','ottawa','tunisia','tunis','indonesia','jakarta']\n",
    "for element in labels:\n",
    "    vec = pca.transform(vecs[element].reshape(1,300))\n",
    "    plt.text(vec[:,0], vec[:,1], element, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-elements",
   "metadata": {},
   "source": [
    "Here we have performed a PCA reduction on ~120 Capital-Country pairs, and we have have tagged some fo them.\n",
    "\n",
    "We can visually experiment with the embedding space: let's consider the case in which we want to know which one is the capital of Chile. If we know that Paris is the capital of France, then we could try adding the vector representing the path between capitals and countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_capitals_subset = ['france','paris','chile','santiago']\n",
    "pca_words = pca.transform([vecs[word] for word in countries_capitals_subset])\n",
    "\n",
    "x_vecs, y_vecs = [v[0] for v in pca_words], [v[1] for v in pca_words]\n",
    "plt.scatter(x_vecs, y_vecs)\n",
    "plt.title('Visualisation of GloVe - countries and capitals')\n",
    "for element in countries_capitals_subset:\n",
    "    vec = pca.transform(vecs[element].reshape(1,300))\n",
    "    plt.text(vec[:,0], vec[:,1], element, fontweight='bold')\n",
    "    \n",
    "# drawing arrows\n",
    "vec_france, vec_paris = pca_words[0], pca_words[1]\n",
    "arrow_france = vec_paris-vec_france\n",
    "plt.arrow(vec_france[0],vec_france[1],arrow_france[0],arrow_france[1])\n",
    "# now we approximate for Chile\n",
    "vec_chile, vec_stgo = pca_words[2], pca_words[3]\n",
    "# theoretical arrow\n",
    "plt.arrow(vec_chile[0],vec_chile[1],arrow_france[0],arrow_france[1],color='red')\n",
    "# actual arrow\n",
    "arrow_chile = vec_stgo-vec_chile\n",
    "plt.arrow(vec_chile[0],vec_chile[1],arrow_chile[0],arrow_chile[1],linestyle=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-laptop",
   "metadata": {},
   "source": [
    "## Section 2: Visualising Semantic Relations\n",
    "\n",
    "You're given a dataset of **adjectives** with their respective **comparatives and superlatives**.\n",
    "\n",
    "For instance: high - higher - highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "with open('data/adjectives.csv') as csvfile: # Change path if necessary\n",
    "    readCSV = csv.reader(csvfile)\n",
    "    for row in readCSV:\n",
    "        #print(len(row[0]))\n",
    "        words.append(row[0])\n",
    "print(words[:6])\n",
    "\n",
    "adj_compa = {}\n",
    "adj_supe = {}\n",
    "#print(int(len(words)/3))\n",
    "for i in np.arange(int(len(words)/3)):\n",
    "    adj = words[3*i-2]\n",
    "    compa = words[3*i-3]\n",
    "    supe = words[3*i-1]\n",
    "    try:\n",
    "        vecs[adj],vecs[compa],vecs[supe]\n",
    "        adj_compa[adj] = compa\n",
    "        adj_supe[adj] = supe\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "all_words = [word for word in adj_compa.keys()]+[word for word in adj_compa.values()] + [word for word in adj_supe.values()]\n",
    "\n",
    "#print(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-participation",
   "metadata": {},
   "source": [
    "### To Do:\n",
    "1. Perform a PCA reduction on the set.\n",
    "2. Visualise this space\n",
    "3. Do you notice that GloVe encodes the relationship between the three kinds of word?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-laugh",
   "metadata": {},
   "source": [
    "**Dimensionality reduction using PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python 3.7.9\n",
    "\n",
    "vector_words = [vecs[word] for word in all_words]\n",
    "\n",
    "pca_adj = PCA(n_components = 3)\n",
    "pca_vecs = pca_adj.fit_transform(vector_words)\n",
    "#vect_projected = pca_adj.transform(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-hunter",
   "metadata": {},
   "source": [
    "Visualisation using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_plot = len(adj_compa)\n",
    "colours = ['tab:blue']*len_plot+['tab:orange']*len_plot+['tab:green']*len_plot\n",
    "x_vecs, y_vecs, z_vecs = [v[0] for v in pca_vecs], [v[1] for v in pca_vecs],[v[2] for v in pca_vecs]\n",
    "plt.scatter(x_vecs, y_vecs,z_vecs, c=colours, marker='o')\n",
    "plt.title('Visualisation of adjectives space')\n",
    "\n",
    "labels = ['rougher', 'rough', 'roughest', 'meaner', 'mean', 'meanest']\n",
    "for element in labels:\n",
    "    vec = pca_adj.transform(vecs[element].reshape(1,300))\n",
    "    plt.text(vec[:,0], vec[:,1], element, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-beads",
   "metadata": {},
   "source": [
    "**Bonus task**\n",
    "1. Take a subset of the words and draw arrows between the three different pairs (adj-com, adj-sup, com-sup), a color for each pair. Is it consistent? \n",
    "2. Can you think of an algorithm to automatically detect whether it is a base adjective, comparative or superlative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "### to do ###\n",
    "adj_compa_subset = [ 'rough','rougher', 'mean', 'meaner' ]\n",
    "adj_supe_subset =['rough', 'roughest',  'mean', 'meanest']\n",
    "pca_compa = pca_adj.transform([vecs[word] for word in adj_compa_subset])\n",
    "pca_supe = pca_adj.transform([vecs[word] for word in adj_supe_subset])\n",
    "\n",
    "x_vecs, y_vecs = [v[0] for v in pca_compa], [v[1] for v in pca_compa]\n",
    "plt.scatter(x_vecs, y_vecs)\n",
    "plt.title('Visualisation of adj-comparative')\n",
    "for element in adj_compa_subset:\n",
    "    vec = pca_adj.transform(vecs[element].reshape(1,300))\n",
    "    plt.text(vec[:,0], vec[:,1], element, fontweight='bold')\n",
    "    \n",
    "# drawing arrows\n",
    "vec_rough, vec_rougher = pca_compa[0], pca_compa[1]\n",
    "arrow_rough = vec_rougher-vec_rough\n",
    "plt.arrow(vec_rough[0],vec_rough[1],arrow_rough[0],arrow_rough[1])\n",
    "# now we approximate for Chile\n",
    "vec_mean, vec_meaner= pca_compa[2], pca_compa[3]\n",
    "# theoretical arrow\n",
    "plt.arrow(vec_mean[0],vec_mean[1],arrow_rough[0],arrow_rough[1],color='red')\n",
    "# actual arrow\n",
    "arrow_mean = vec_meaner-vec_mean\n",
    "plt.arrow(vec_mean[0],vec_mean[1],arrow_mean[0],arrow_mean[1],linestyle=':')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}